# Librarian Support System

__Date :__ 2024-June-24

__Author :__ Duwon Yang 21900427, Soonho Lim

__Github :__ [LINK](https://github.com/snowlunatic/DLIP)

__DEMO__ : [LINK](https://youtu.be/gJocIE2mtVA)

## Introduction

<figure align="center">
<img src="https://github.com/snowlunatic/image/assets/115797946/cb1fac22-b876-4dd0-9346-f84ccbe04f6f"width="70%">
  <figcaption><em>Fig1. Librarian Asistant System</em></figcaption>
</figure>


Librarians in a library primarily handle tasks such as finding returned books and arranging books in order. However, these tasks are time-consuming and prone to errors as they require manual inspection of small labels. To address these issues, I propose a system that, by taking a photo of the book spines, can verify the correct arrangement based on the labels or provide the location of the desired book.

​	This system would use image recognition technology to read the labels on the spines of the books. By comparing the recognized labels to the database, it can determine if the books are in the correct order. If any books are misplaced, the system would alert the librarian, specifying which books need to be rearranged.

​	Additionally, for finding specific books, the system could take a query (either by title, author, or ISBN), and then guide the librarian to the exact location of the book within the library. This would significantly reduce the time spent searching for books and improve overall efficiency.

​	Such a system would leverage advancements in computer vision and machine learning, ensuring accurate and quick verification and search processes. By integrating this technology into library management, librarians can focus on more critical and engaging tasks, enhancing the overall library experience for patrons.



## Requirement

__Software__

+ OpenCV 4.9.0, Visual Studio Code (ver1.88.1)
+ OpenCV-Python 3.9.18 
+ Yolov8x
+ Google Cloud Vision API

__Dataset__

+  Images of library bookshelves (self-taked)



## Installation

### Step 1. Install Anaconda

__Anaconda__ : Python and libraries package installer

Follow : [How to install Anaconda](https://ykkim.gitbook.io/dlip/installation-guide/anaconda#conda-installation)

### Step 2. Install Python

Python is already installed by installing Anaconda. But, we will make a virtual environment for a specific Python version.

Open Anaconda Prompt(admin mode)

<figure align="center">
<img src="https://github.com/dduiddui/Deep-Learning-Image-Processing/assets/121938154/e72c5db9-8faf-4c10-aa5e-bbef1d395a8e"width="90%">
  <figcaption><em>Fig2. Anaconda install</em></figcaption>
</figure>



First update conda

```bash
conda update -n base -c defaults conda
```


Then, Create virtual environment for Python 3.9. Name the $ENV as py39. If you are in base, enter conda activate py39

```bash
conda create -n py39 python=3.9.12
```

After installation, activate the newly created environment

```bash
conda activate py39
```

### Step 3. Install Libs

Install Numpy, OpenCV, Matplot, Jupyter

```bash
conda activate py39
conda install -c anaconda seaborn jupyter
pip install opencv-python
```

### Step 4. Install Visual Studio Code

Follow : [How to Install VS Code](https://ykkim.gitbook.io/dlip/installation-guide/ide/vscode#installation)

### Step 5. Install Graphic Card and CUDA

Follow : [How to install Driver, CUDA and cuDNN](https://ykkim.gitbook.io/dlip/installation-guide/cuda-installation)

### Step 6. Install Pytorch

___Without GPU(Only CPU)__

```bash
# CPU Only - PyTorch 2.1
conda install pytorch==2.1.1 torchvision==0.16.1 torchaudio==2.1.1 cpuonly -c pytorch
pip install opencv-python torchsummary


# CPU Only - PyTorch 1.9
conda install -c anaconda seaborn jupyter
conda install pytorch==1.9.1 torchvision==0.10.1 torchaudio==0.9.1 cpuonly -c pytorch
pip install opencv-python torchsummary
```

___With GPU__ Change the PyTorch version depending on your CUDA version

```bash
# CUDA 11.8
conda activate py39

conda install -c anaconda cudatoolkit=11.8 cudnn seaborn jupyter
conda install pytorch=2.1 torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
pip install opencv-python torchsummary
```

__Check GPU in PyTorch__

```bash
conda activate py39
python
import torch
torch.__version__
print("cuda" if torch.cuda.is_available() else "cpu")
```

The result should be ```cuda```.

If your result is ```cpu```, Go to [Troubleshooting](https://ykkim.gitbook.io/dlip/installation-guide/installation-guide-for-deep-learning#troubleshooting)

### Step 7. Install Yolov8 via pip package

First, activate the environment AND Install YOLOv8 with pip to get stable packages

```bash
conda activate py39
pip install ultralytics
pip install onnx
```

and more information about [Examples](https://ykkim.gitbook.io/dlip/deep-learning-for-perception/dp-tutorial/tutorial-yolo-in-pytorch/tutorial-yolov8-in-pytorch)


### Step 8. Install Google Cloud Vision API

Get into the [link](https://cloud.google.com/vision?hl=en)

Click the ```Try Vision AI free``` and register your credit card number

+  Although this product is paid, a 90-day free trial is available.

<figure align="center">
<img src="https://github.com/dduiddui/Deep-Learning-Image-Processing/assets/121938154/5ab6e49a-2aad-428e-a661-aff270b451c3"width="90%">
  <figcaption><em>Fig3. 
Google Cloud Vision install</em></figcaption>
</figure>



Click the ```My First Project```

<figure align="center">
<img src="https://github.com/dduiddui/Deep-Learning-Image-Processing/assets/121938154/93f820d3-31dc-4b00-a8b9-defc853be77f"width="90%">
  <figcaption><em>Fig4. 
Google Cloud Vision install</em></figcaption>
</figure>



Click the ```New Project```

<figure align="center">
<img src="https://github.com/dduiddui/Deep-Learning-Image-Processing/assets/121938154/fd0575ad-0e88-4faf-b5c5-6d6bc7a13bd8"width="90%">
  <figcaption><em>Fig5. 
Google Cloud Vision install</em></figcaption>
</figure>



Follow the instruction

<figure align="center">
<img src="https://github.com/dduiddui/Deep-Learning-Image-Processing/assets/121938154/e7ca712a-9292-4b4f-a9f4-483cb6f0d58e"width="90%">
  <figcaption><em>Fig6. 
Google Cloud Vision install</em></figcaption>
</figure>



Create Service Account

<figure align="center">
<img src="https://github.com/dduiddui/Deep-Learning-Image-Processing/assets/121938154/9ce55e6e-d277-4c16-b085-be6c3818f52c"width="90%">
  <figcaption><em>Fig7. 
Google Cloud Vision install</em></figcaption>
</figure>



Select a role as editor or owner

<figure align="center">
<img src="https://github.com/dduiddui/Deep-Learning-Image-Processing/assets/121938154/6d6207d8-8814-40f8-b296-a4d1f427fa91"width="90%">
  <figcaption><em>Fig8. 
Google Cloud Vision install</em></figcaption>
</figure>



Go into the Key manager

<figure align="center">
<img src="https://github.com/dduiddui/Deep-Learning-Image-Processing/assets/121938154/94c2aae2-07c2-46e9-8a04-c7e53e7849f0"width="90%">
  <figcaption><em>Fig9. 
Google Cloud Vision install</em></figcaption>
</figure>



Select JSON as the key type, then click Create

<figure align="center">
<img src="https://github.com/dduiddui/Deep-Learning-Image-Processing/assets/121938154/09e1014c-4b36-4757-ba90-0dde1d9ba3fd"width="90%">
  <figcaption><em>Fig10. 
Google Cloud Vision install</em></figcaption>
</figure>



Package Installation

```bash
pip install google-cloud-vision google-auth
```

Setting the Key File

```bash
export GOOGLE_APPLICATION_CREDENTIALS="path/to/your/service-account-file.json"
```




## Flow Chart

<figure align="center">
  <img src="https://github.com/dduiddui/Deep-Learning-Image-Processing/assets/121938154/e57d76bc-b32f-41dd-9e30-c9bf2ab1354c" style="width:90%;">
  <figcaption><em>Fig11. The Blockdiagram of Librarian Support System</em></figcaption>
</figure>




The algorithm detailed above is intended to determine the label of a book by specifying a Region of Interest (ROI). In order to accomplish this, a pretrained YOLOv8x model is utilized for the detection of books according to their dimensions. Furthermore, the Google Cloud Vision API is utilized for text detection. This system enables the identification of specific books upon input, confirming their arrangement and offering direction on their display.



## Procedure

### Book detection & ROI setting

​	First step of the program is detecting books and setting ROIs for the book labels for text detection. Otherwise Google Cloud Vision will detected unwanted texts on the side of the book. The project uses 'yolov8x' for precise detection.  

```python
import cv2
from ultralytics import YOLO
import roiF as roi
import op1F as op1
import op2F as op2

# Load YOLO model
model = YOLO('yolov8x.pt')
image_path = 'data/3.jpg'

# Read image
image = cv2.imread(image_path)

# Check if the image is loaded correctly
if image is None:
    raise FileNotFoundError(f"Image not found at {image_path}")

# Perform object detection on the image
result = model.predict(source=image, save=True, save_txt=True)

# Process ROI (Region of Interest)
roi_info, final_roi_info = roi.set_roi(image, result)
```

The predicted result is used for setting ROIs with the function `set_roi` in other module `roiF` imported as roi. 



```python
def set_roi(image, result, threshold=0.6):
    roi_info = []
    for r in result:
        book = 0
        boxes = r.boxes
        centerPoints = []
        valid_boxes = []

        # Process each detected box
        for box in boxes:
            confidence = box.conf[0]
            if confidence > threshold:  # Filter by confidence score
                class_id = int(box.cls)
                if class_id == 73:  # Check if the class is "book"
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    centerPoint = (int((x2 - x1) // 2 + x1), int((y2 - y1) // 2 + y1))
                    centerPoints.append(centerPoint)
                    valid_boxes.append((x1, y1, x2, y2, centerPoint))
        
        # Check if boxes overlap
        for i, (x1, y1, x2, y2, centerPoint) in enumerate(valid_boxes):
            count = sum(is_point_in_box(cp, (x1, y1, x2, y2)) 
                        for j, (cx1, cy1, cx2, cy2, cp) in enumerate(valid_boxes) if i != j)
            if count < 2:  # If not overlapping with more than one box
                book += 1
                roi = image[y1:y2, x1:x2]  # Extract the ROI from the image
                roi_info.append((x1, y1, x2, y2, roi))  # Add ROI info to the list
        
        # Sort ROIs by the x-coordinate of the bounding boxes
        roi_info.sort(key=lambda x: x[0])

    final_roi_info = []
    # Process ROI information
    for idx, (x1, y1, x2, y2, roi) in enumerate(roi_info):
        roi_number = idx + 1
        height = y2 - y1
        new_height = height // 4

        # Select the bottom quarter of the ROI
        sub_y1 = y1 + 3 * new_height
        sub_y2 = y2
        sub_roi = image[sub_y1:sub_y2, x1:x2]

        # Divide the selected part into top and bottom halves
        sub_height = sub_y2 - sub_y1
        mid_y = sub_y1 + sub_height // 2

        # Use only the upper part
        upper_roi = image[sub_y1-20:mid_y, x1:x2]
        final_roi_info.append((x1, sub_y1, x2, mid_y, upper_roi, roi_number))

    # Sort final ROI by the x-coordinate
    final_roi_info.sort(key=lambda x: x[0])
    
    return roi_info, final_roi_info
```

​	The `set_roi` function processes an image and its detection results to identify and filter regions of interest (ROIs) classified as books. The function starts by initializing an empty list, `roi_info`, to store detected ROIs. It iterates through the detection results, filtering boxes by confidence score and classifying them as "book" if they meet the threshold. For valid detections, it calculates bounding box coordinates and center points, storing these in lists.

​	The function checks for overlapping boxes, counting how many other center points fall within each valid box. Non-overlapping boxes are considered valid, and their ROIs are extracted and added to `roi_info`, which represents the detected book regions.

​	Further processing involves dividing each ROI vertically into quarters, selecting the bottom quarter, and then using only the upper half of this section. These refined ROIs, focusing on the part of the book where the label is typically located, are stored in `final_roi_info` with their respective ROI numbers and sorted by x-coordinate.



```python
def is_point_in_box(point, box):
    # Unpack the coordinates of the box
    x1, y1, x2, y2 = box
    # Unpack the coordinates of the point
    px, py = point
    # Check if the point is within the bounds of the box
    return x1 <= px <= x2 and y1 <= py <= y2
```

​	The `is_point_in_box` function checks if a given point lies within the bounds of a specified box. It returns `True` if the point's coordinates are within the box's coordinates, otherwise it returns `False`.



### Text detection

​	Step two is to detect the text form the label which is in the ROI. 

```python
# Text detection
text_result = roi.text_detect(final_roi_info)

# Print detected text results
for i, result in enumerate(text_result):
    print(f"Entry {i}: {result}")
```

Text detection is in the function `text_detect` which is in the same module as the ROI setting.



```python
def text_detect(final_roi_info):
    roi_number = 0
    detected_texts = []
    text = [] 
    text_result = [] 

    for textd in final_roi_info:
        x1, sub_y1, x2, mid_y, roi_image, _ = textd
        # Convert the ROI image to grayscale
        gray_roi = cv2.cvtColor(roi_image, cv2.COLOR_BGR2GRAY)
        # Apply binary thresholding to the grayscale image
        _, thresh = cv2.threshold(gray_roi, 150, 255, cv2.THRESH_BINARY)
        # Detect text from the thresholded image
        detected_texts_list = detect_text(thresh)  # Assume detect_text returns a list of tuples
        # Extract only the text parts from the detection results
        detected_texts_only = [text for text, _ in detected_texts_list]
        # Filter out non-English and non-numeric characters except '.'
        filtered_texts_only = []
        for t in detected_texts_only:
            filtered_text = re.sub(r'[^a-zA-Z0-9.\s]', '', t)
            if filtered_text.strip():  # Add only if there is remaining text
                filtered_texts_only.append(filtered_text)
        detected_texts.append((filtered_texts_only, roi_number))
        
        if filtered_texts_only:
            filtered_text = filtered_texts_only[0]
            # Further split by '\n' and filter out chunks with two or more consecutive letters
            chunks = filtered_text.split('\n')
            valid_chunks = [chunk for chunk in chunks if not re.search(r'[a-zA-Z]{2,}', chunk)]
            # Join valid chunks back with '\n'
            final_text = '\n'.join(valid_chunks)
            # Remove leading non-numeric characters and leading \n and spaces from the first chunk
            if final_text:
                cleaned_final_text = re.sub(r'^[^\d\n]*', '', final_text).lstrip()
                lines = cleaned_final_text.split('\n')
                category = lines[0] if len(lines) > 0 else ""
                sub_alpha = ""
                sub_category = ""
                year = lines[2] if len(lines) > 2 else ""
                # If there is a second line, process it
                if len(lines) > 1:
                    second_line = lines[1]
                    # Remove leading '.' from the second line
                    if second_line.startswith('.'):
                        second_line = second_line[1:]
                    # Split alpha and numeric parts in the second line
                    parts = re.findall(r'[^\W\d_]+|\d+', second_line)
                    if len(parts) > 0:
                        sub_alpha = parts[0]  # First part is alpha
                    if len(parts) > 1:
                        sub_category = parts[1]  # Second part is numeric

                # Post-process category to remove leading zeros and convert to float
                if category:
                    category = re.sub(r'^0+', '', category)
                    category = float(category) if category else 0.0

                # Post-process sub_category to int and adjust to 3 digits
                if sub_category:
                    sub_category = int(sub_category)
                    if sub_category < 10:
                        sub_category *= 100
                    elif sub_category < 100:
                        sub_category *= 10

                # Post-process year to int
                if year:
                    year = int(year)

                text.append([cleaned_final_text])
                text_result.append({
                    "book_number": roi_number,
                    "category": category,
                    "sub_alpha": sub_alpha,
                    "sub_category": sub_category,
                    "year": year
                })
        roi_number += 1

    return text_result

```

​	First, the code initializes variables: `roi_number` to track the current ROI, `detected_texts` to store detected text, `text` for filtered text, and `text_result` for the final processed results.

​	The code then processes each ROI by extracting coordinates and converting the ROI image to grayscale. Binary thresholding is applied to distinguish text from the background. The `detect_text` function is used to detect text, and non-English/non-numeric characters are filtered out.

​	For each filtered text, the code splits it into chunks, filters out chunks with consecutive letters, and cleans leading non-numeric characters. It extracts `category`, `sub_alpha`, `sub_category`, and `year` from the cleaned text, converts these to appropriate formats, and stores the results in `text_result`. The process repeats for all ROIs.



### Option Selection

​	Next step is selecting the options for the program. Option 1 is for finding a specific book and option 2 is inspecting misplaced books and giving the right arrangement.

```python
# Option selection for further processing
print("Option 1 for finding book\nOption 2 for arranging misplaced book")
option = int(input("Press '1' for option 1, press '2' for option 2: "))

OPchoice = False

if option == 1:
    OPchoice = True
elif option == 2:
    OPchoice = False
else:
    pass
```



### Option 1

​	If the `OPchioce` is true option 1 run through the program.

```python
# ==================== option 1 program ==================== # 
if OPchoice:
    # Execute option 1 function
    image = op1.finding_book(image, text_result, roi_info)
```

The function of finding specific book, `finding_book` is in module `op1F`. 



```python
def finding_book(image, text_result, roi_info):
    # Get user input for the book search
    user_input = get_user_input()
    # Find the matching ROI number based on user input
    roi_number = find_matching_roi_number(user_input, text_result)

    # Define the dimensions and position for the result display box
    height, width, _ = image.shape
    box_height = height // 10
    box_width = width // 3
    box_start_y = height - box_height
    box_start_x = width - box_width
    box_end_y = height
    box_end_x = width
    # Draw a black rectangle for the result display box
    cv2.rectangle(image, (box_start_x, box_start_y), (box_end_x, box_end_y), (0, 0, 0), -1)

    if roi_number is not None:
        # Print and display the matching book number
        print(f"Matching Book Number: {roi_number + 1}")
        x1, y1, x2, y2, cp = roi_info[roi_number]
        cv2.putText(image, f"BOOK Found {roi_number + 1}", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 180, 170), 5)
        cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 15)
        text = "The Book number is " + str(roi_number + 1)
    else:
        # Print and display message when no matching result is found
        print("No matching result found.")
        text = "No matching Book."

    # Calculate the text size and position for centered alignment in the result display box
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 2.5
    thickness = 3
    text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)
    text_width, text_height = text_size
    text_x = box_start_x + (box_width - text_width) // 2
    text_y = box_start_y + (box_height + text_height) // 2

    # Add the text to the image
    cv2.putText(image, text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness)

    return image
```

The `finding_book` function highlights a specific book in an image based on user input. It starts by getting the user's search input and finding the matching region of interest (ROI) in the `text_result`. It then sets up a display box at the bottom right of the image to show the result.

If a matching book is found, the function highlights the book with a red rectangle and displays its number. If no match is found, it shows a "No matching Book" message. The result text is centered in the display box. The function returns the image with the highlighted book and result text.



```python
def get_user_input():
    # Prompt user for input and store the responses
    category = float(input("Enter category: "))
    sub_alpha = input("Enter sub alpha: ")
    category_digits = int(input("Enter category digits (three digits): "))
    year = int(input("Enter year: "))
    
    # Return the user input as a dictionary
    return {
        'category': category,
        'sub_alpha': sub_alpha,
        'sub_category': category_digits,
        'year': year
    }
```

​	The `get_user_input` function prompts the user to enter details about a book, including category, sub alpha, category digits, and year. It returns these inputs as a dictionary.



```python
def find_matching_roi_number(user_input, results):
    # Iterate through each result in the list of results
    for result in results:
        # Check if all fields match between user input and result
        if (
            user_input['category'] == result['category'] and
            user_input['sub_alpha'] == result['sub_alpha'] and
            user_input['sub_category'] == result['sub_category'] and 
            user_input['year'] == result['year']
        ):
            # Return the book number if a match is found
            return result['book_number']
    # Return None if no match is found
    return None
```

​	The `find_matching_roi_number` function compares user input with a list of results to find and return the matching book number. If no match is found, it returns `None`.



### Option 2

​	If `OPchoice` is False option 2 run through the program and this option give information of misplaced books and show how to rearrange it. 

```python
# ==================== option 2 program ==================== # 
else:
    # Find books that do not belong
    dif_cat, major_category, major_alpha = op2.find_notBelong(text_result)
    print("different category", dif_cat)
    if dif_cat:
        # draw box in the result image
        image = op2.draw_notBelong(image, roi_info, dif_cat)
  
    # Find books that are not arranged properly
    w_alpha, w_cat, w_year = op2.find_notArranged(text_result, major_category, major_alpha)
    image = op2.draw_notArranged(image, roi_info, text_result, major_alpha, w_alpha, w_cat, w_year)
    # draw arrows and text box in the result image
    image = op2.text_box(image, dif_cat, w_alpha, w_cat, w_year)
```

The function `find_notBelong` , `find_notArranged`, `draw_notBelong` , `draw_notArranged` and `text_box`  are in the module `op2F`. 



```python
def find_notBelong(text_result):
    # Count the occurrences of each category and sub_alpha in text_result
    category_counts = Counter(result['category'] for result in text_result)
    alphabet_counts = Counter(result['sub_alpha'] for result in text_result)

    # Find the most frequent Category and Alphabet with a frequency of 3 or more
    major_category = max((cat for cat in category_counts if category_counts[cat] >= 3), 
                        key=lambda x: category_counts[x], default=None)
    major_alphabet = max((alpha for alpha in alphabet_counts if alphabet_counts[alpha] >= 3), 
                        key=lambda x: alphabet_counts[x], default=None)

    # Find book_numbers with a different Category value
    dif_cat = [result['book_number'] for result in text_result if result['category'] != major_category]

    return dif_cat, major_category, major_alphabet
```

​	The `find_notBelong` function identifies the most frequent category and sub-alphabet in a given list of text results and finds book numbers that do not belong to the most frequent category. It counts the occurrences of each category and sub-alphabet using the `Counter` class, then determines the most frequent values that appear three or more times. Finally, it compiles a list of book numbers whose category differs from the most frequent category, and returns this list along with the most frequent category and sub-alphabet.



```python
def draw_notBelong(image, roi_info, dif_cat):
    # Check if there are any book numbers with different categories
    if dif_cat:
        ## Category is different
        # Draw a box and an X mark on the ROI with different category values on the original image
        for roi_count in dif_cat:
            print("roicount", roi_count)
            for x1, y1, x2, y2, roi in roi_info:
                # Check if the current ROI index matches the roi_count
                if roi_info.index((x1, y1, x2, y2, roi)) == roi_count:
                    print(roi_info.index((x1, y1, x2, y2, roi)))
                    # Draw a bounding box around the ROI
                    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 10)
                    # Put a text label "BOOK {roi_count+1}" above the bounding box
                    cv2.putText(image, f"BOOK {roi_count+1}", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 5)
                    # Draw an X mark over the ROI
                    cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 10)
                    cv2.line(image, (x2, y1), (x1, y2), (0, 0, 255), 10)

    return image
```

​	The `draw_notBelong` function visually marks Regions of Interest (ROIs) in an image that have categories differing from the most frequent category. It first checks if the `dif_cat` list, which contains the book numbers with different categories, is not empty. For each book number in `dif_cat`, the function locates the corresponding ROI in the `roi_info` list. When it finds a matching ROI, it draws a red bounding box around the ROI, places a text label "BOOK {roi_count+1}" above the bounding box, and draws a red X mark over the ROI. These visual markers make it easy to identify which books do not belong to the predominant category. The function returns the modified image with these annotations.



```python
def find_notArranged(text_result, major_category, major_alphabet):
    # Initialize lists to store book numbers that are out of order
    w_alpha, w_cat, w_year = [], [], []
    # Initialize previous alpha, category, and year for comparison
    p_alpha, p_cat, p_year = None, None, None

    # Iterate through each text result
    for text in text_result:
        category, alpha, cat, year, book_num = text['category'], text['sub_alpha'], text['sub_category'], text['year'], text['book_number']
        
        # Check if the current category matches the major category
        if category == major_category:
            # Ensure previous values and major_alphabet are available for comparison
            if p_alpha and p_cat and p_year and major_alphabet:
                # Check if the current sub_alpha does not match the major alphabet
                if alpha != major_alphabet:
                    # Exclude the first and last book from the comparison
                    if book_num != text_result[0]['book_number'] and book_num != text_result[len(text_result)-1]['book_number']:
                        w_alpha.append(book_num)

                # Check if the current sub_alpha matches the previous one
                if p_alpha == alpha:
                    # Compare sub_category values
                    if p_cat > cat:
                        w_cat.append(book_num)
                    # If sub_category values are the same, compare year values
                    elif p_cat == cat:
                        if p_year > year:
                            w_year.append(book_num - 1)

        # Update previous values for the next iteration
        p_alpha, p_cat, p_year = alpha, cat, year

    # Return the lists of book numbers that are out of order
    return w_alpha, w_cat, w_year

```

​	The `find_notArranged` function identifies book numbers that are not properly arranged based on sub-alphabet, sub-category, and year within a list of text results. It initializes lists to store out-of-order book numbers and variables to keep track of the previous values for comparison. As it iterates through each entry in `text_result`, it checks if the current category matches the `major_category`. If it does, it performs several checks: adding the book number to `w_alpha` if the current sub-alphabet doesn't match the `major_alphabet`, excluding the first and last books; adding to `w_cat` if the current sub-category is out of order; and adding to `w_year` if the current year is out of order. The function updates previous values for each entry and returns the lists of out-of-order book numbers.



```python
def draw_notArranged(image, roi_info, text_result, major_alphabet, w_alpha, w_cat, w_year):
    # Draw rectangles and arrows for book numbers that have out-of-order alphabets
    if w_alpha and major_alphabet:
        for count in range(len(w_alpha)):
            x1, y1, x2, y2, cp = roi_info[w_alpha[count]]
            color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))  # Random color for year discrepancies
            cv2.rectangle(image, (x1, y1), (x2, y2), color, 10)
            print("alphabet: ", text_result[w_alpha[count]]['sub_alpha'])

            # Determine the direction for the arrow based on the sub_alpha comparison
            if text_result[w_alpha[count]]['sub_alpha'] > major_alphabet:
                dir = "right"
            else:
                dir = "left"
            print("dir: ", dir)
            Horizontal_arrow(image, w_alpha[count], color, roi_info, dir)
    
    # Draw rectangles and arrows for book numbers that have out-of-order categories
    if w_cat:
        count = 0
        for roi_num in w_cat:
            x1, y1, x2, y2, cp = roi_info[w_cat[count]]
            color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))  # Random color for category discrepancies
            cv2.rectangle(image, (x1, y1), (x2, y2), color, 10)

            current_item = text_result[roi_num]
            filtered_items = [
                item for item in text_result if
                item['sub_alpha'] == current_item['sub_alpha'] 
            ]
            # Sort filtered items by sub_category
            sort_cat = sorted(filtered_items, key=lambda x: x['sub_category'])
            df = pd.DataFrame(sort_cat)
            print(df)
            position = next((index for index, result in enumerate(sort_cat) if result['book_number'] == roi_num), None)
            print("position:", position)

            if position is not None:
                if position == len(sort_cat) - 1:
                    # If the current item is the last one, use the previous item's ROI number
                    neighbor_position = position - 1
                else:
                    # Otherwise, use the next item's ROI number
                    neighbor_position = position + 1
                
                if neighbor_position >= 0 and neighbor_position < len(sort_cat):
                    neighbor_roi_number = sort_cat[neighbor_position]['book_number']
                    print(f"Current ROI Number: {roi_num}, Neighbor ROI Number: {neighbor_roi_number}")
                    pos = None
                    if roi_num > neighbor_roi_number:
                        pos = "front"
                        print(pos)
                    else:
                        pos = "back"
                        print(pos)
                    draw_arrow(image, neighbor_roi_number, color, roi_info, pos)
            count += 1

    # Draw rectangles and arrows for book numbers that have out-of-order years
    if w_year:
        count = 0
        for roi_num in w_year:
            x1, y1, x2, y2, cp = roi_info[w_year[count]]
            color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))  # Random color for year discrepancies
            cv2.rectangle(image, (x1, y1), (x2, y2), color, 10)

            current_item = text_result[roi_num]
            filtered_items = [
                item for item in text_result if
                item['sub_alpha'] == current_item['sub_alpha'] and
                item['sub_category'] == current_item['sub_category'] 
            ]
            # Sort filtered items by year
            sort_year = sorted(filtered_items, key=lambda x: x['year'])
            df = pd.DataFrame(sort_year)
            print(df)
            position = next((index for index, result in enumerate(sort_year) if result['book_number'] == roi_num), None)
            print("position:", position)

            if position is not None:
                if position == len(sort_year) - 1:
                    # If the current item is the last one, use the previous item's ROI number
                    neighbor_position = position - 1
                else:
                    # Otherwise, use the next item's ROI number
                    neighbor_position = position + 1
                
                if neighbor_position >= 0 and neighbor_position < len(sort_year):
                    neighbor_roi_number = sort_year[neighbor_position]['book_number']
                    print(f"Current ROI Number: {roi_num}, Neighbor ROI Number: {neighbor_roi_number}")
                    pos = None
                    if roi_num > neighbor_roi_number:
                        pos = "front"
                        print(pos)
                    else:
                        pos = "back"
                        print(pos)
                    draw_arrow(image, neighbor_roi_number, color, roi_info, pos)
            count += 1

    return image
```

​	The `draw_notArranged` function highlights ROIs (Regions of Interest) in an image that are not properly arranged based on sub-alphabet, sub-category, and year. It first processes the `w_alpha` list, drawing green rectangles around ROIs with out-of-order sub-alphabets and adding horizontal arrows indicating the direction of discrepancy. Next, it handles the `w_cat` list by drawing random-colored rectangles around ROIs with out-of-order sub-categories, filtering and sorting these items by sub-category, and drawing arrows to indicate whether the current ROI should be moved in front of or behind its neighboring ROI. Finally, it addresses the `w_year` list similarly, drawing random-colored rectangles around ROIs with out-of-order years, filtering and sorting by year, and drawing arrows to show the correct order relative to neighboring ROIs. This function helps visually identify and correct misarranged items in the image.



```python
def text_box(image, dif_cat, w_alpha, w_cat, w_year):
    # Combine all wrong book numbers into one list and increment by 1 for display
    wrong_books = dif_cat + w_alpha + w_cat + w_year
    wrong_books = [x + 1 for x in wrong_books]
    
    # Get the dimensions of the image
    height, width, _ = image.shape
    
    # Set the messages based on whether there are misplaced books or not
    if wrong_books:
        text2 = "Misplaced books: " + str(wrong_books)
        text3 = "Replace the book following the arrow"
    else:
        text2 = "NO Misplaced Books"
        text3 = "Great job"
    
    # Define the texts to display
    texts = ["Book detected: " + str(len(wrong_books)), text2, text3]
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 2
    font_color = (255, 255, 255)
    thickness = 5
    
    # Calculate the size of each text and determine the height of the largest text
    text_sizes = [cv2.getTextSize(text, font, font_scale, thickness)[0] for text in texts]
    max_text_height = max([size[1] for size in text_sizes])
    
    # Set the size of the box
    padding = 40
    box_height = height // 10
    box_width = max([size[0] for size in text_sizes]) + padding * 2
    
    # Position the box at the bottom right corner
    top_left = (width - box_width, height - box_height)
    bottom_right = (width, height)
    
    # Draw a black rectangle as the box
    cv2.rectangle(image, top_left, bottom_right, (0, 0, 0), -1)
    
    # Draw each text on the image within the box
    start_y = top_left[1] + padding
    for i, text in enumerate(texts):
        text_size = text_sizes[i]
        text_x = top_left[0] + (box_width - text_size[0]) // 2
        text_y = start_y + i * (max_text_height + padding) + text_size[1]
        cv2.putText(image, text, (text_x, text_y), font, font_scale, font_color, thickness)
    
    return image
```

​	The `text_box` function adds a text box to an image to display misplaced book information. It combines book numbers, retrieves image dimensions, sets messages, and calculates text sizes. It positions a black rectangle at the bottom right and centers each text within it. The function returns the modified image with the text box.



```python
def draw_arrow(im, book_number, color, roi_point, pos):
    # Get the coordinates of the ROI for the given book number
    x1, y1, x2, y2, cp = roi_point[book_number]

    # Determine the x-location for the arrow based on the position ('front' or 'back')
    if pos == "front":
        x_location = x1
    elif pos == "back":
        x_location = x2

    # Calculate the end point of the arrow
    arrow_end_y = y1 + round((y1 - y2) * 0.1)

    # Draw the arrowed line on the image
    cv2.arrowedLine(im, (x_location, arrow_end_y), (x_location, y1), color, 12, tipLength=0.3)
```

​	The `draw_arrow` function draws an arrow on the image to indicate the position of a book. It retrieves the coordinates of the ROI for the specified book number and determines the x-location based on whether the arrow should point to the 'front' or 'back' of the book. It calculates the end point of the arrow and uses `cv2.arrowedLine` to draw the arrow on the image, using the specified color and line thickness.



```python
def Horizontal_arrow(im, book_num, color, roi_point, dir):
    print(book_num)
    # Get the coordinates of the ROI for the given book number
    x1, y1, x2, y2, cp = roi_point[book_num]

    # Initialize start and end points for the arrow
    start_point = None
    end_point = None

    # Calculate the center and width of the box
    center_x = (x1 + x2) // 2
    center_y = (y1 + y2) // 2
    box_width = x2 - x1
    arrow_length = box_width // 3

    # Determine the start and end points for the arrow based on direction
    if dir == "right":
        start_point = center_x + arrow_length
        end_point = center_x
        cv2.arrowedLine(im, (end_point, center_y), (start_point, center_y), color, 15, tipLength=0.5)
    elif dir == "left":
        start_point = center_x
        end_point = center_x - arrow_length
        cv2.arrowedLine(im, (start_point, center_y), (end_point, center_y), color, 15, tipLength=0.5)

    else:
        pass
```

​	The `Horizontal_arrow` function draws a horizontal arrow on the image to indicate direction. It first retrieves the coordinates of the ROI for the given book number. The center and width of the ROI box are calculated to determine the starting and ending points of the arrow. If the direction is "right," the arrow is drawn from the center to the right. If the direction is "left," the arrow is drawn from the center to the left. The `cv2.arrowedLine` function is used to draw the arrow on the image with the specified color and line thickness. If the direction is neither "right" nor "left," the function does nothing.



## Result

### Option 1

The image that was subjected was:

<figure align="center">
  <img src="https://github.com/snowlunatic/image/assets/115797946/06f44b57-8c15-418b-a774-2b349bd7375b" style="width:50%;">
  <figcaption><em>Fig12. Image for Option 1</em></figcaption>	
</figure>



|              |  Book 1  |  Book 2  |  Book 3  |  Book 4  |  Book 5  |
| ------------ | :------: | :------: | :------: | :------: | :------: |
| Category     | 621.3815 | 621.3815 | 621.3815 | 621.3815 | 621.3815 |
| Alphabet     |    N     |    N     |    N     |    N     |    N     |
| Sub-Category |    38    |    42    |    42    |    52    |    67    |
| Year         |   2007   |   2007   |   2007   |   2003   |   1997   |



##### When the existing values were entered:

*Enter category: 621.3815*
*Enter sub alpha: N*
*Enter category digits (three digits): 380*
*Enter year: 2007*
*Matching Book Number: 1*</u>

<figure align="center">
  <img src="https://github.com/snowlunatic/image/assets/115797946/c939617a-9aec-4bee-b3d4-9afb8331e891" style="width:70%;">
  <figcaption><em>Fig13. Result when the book is found</em></figcaption>
</figure>



​	If the book which is being searched is found, it bounds the book with blue box to show the found book and prints out the book number.



##### When non-existing values were entered:

*Enter category: 621.2*
*Enter sub alpha: F*
*Enter category digits (three digits): 620*
*Enter year: 1999*
*No matching result found.*

<figure align="center">
  <img src="https://github.com/snowlunatic/image/assets/115797946/af4de65a-6ea5-473f-a67e-407a7b4bf4fa" style="width:70%;">
  <figcaption><em>Fig14. Result when there is no book</em></figcaption>
</figure>



If the book is not found, it prints out the text "No matching Book".



### Option 2

​	In the option 2, there are 5 possible way of results: 1. No misplaced 2. Wrong Category 3. Wrong Alphabet 4. Wrong Sub-category 5. Wrong Year. For each cases 5 different image is given to analyze. 

##### "No misplaced":

​	If nothing is misplaced, it just shows the number of book detected and tells that there is no misplaced book.

<figure align="center">
  <img src="https://github.com/snowlunatic/image/assets/115797946/f611480a-ef54-4bca-b3ac-487b5ed98564" style="width:70%;">
  <figcaption><em>Fig15. No book misplaced</em></figcaption>
</figure>



|              | Book 1 | Book 2 | Book 3 | Book 4 | Book 5 |
| ------------ | :----: | :----: | :----: | :----: | :----: |
| Category     |  5.1   |  5.1   |  5.1   |  5.1   |  5.1   |
| Alphabet     |   M    |   M    |   M    |   M    |   M    |
| Sub-Category |   3    |   3    |   32   |   32   |   32   |
| Year         |  2004  |  2005  |  2003  |  2012  |  2017  |



##### "Wrong Category":

​	If the category is wrong, it will bound with a red cross box and prints out number of the misplaced book. 

<figure align="center">
  <img src="https://github.com/snowlunatic/image/assets/115797946/9f7ed565-d033-4428-9dd6-32a45d5ca253" style="width:70%;">
  <figcaption><em>Fig16. Wrong Category</em></figcaption>
</figure>



|              | Book 1 | Book 2 | Book 3 | *<u>Book 4</u>* | Book 5 | Book 6 |
| ------------ | :----: | :----: | :----: | :-------------: | :----: | :----: |
| Category     |  5.12  |  5.12  |  5.12  |  *<u>5.12</u>*  |  5.12  |  5.12  |
| Alphabet     |   D    |   F    |   F    |   *<u>J</u>*    |   F    |   G    |
| Sub-Category |   3    |   3    |   32   |   *<u>32</u>*   |   44   |   35   |
| Year         |  2004  |  2005  |  2003  |  *<u>2012</u>*  |  2017  |  2002  |



##### "Wrong Alphabet":

​	If there is a wrong alphabet order it will show the direction where the misplaced should go and same as the other results shows the number of the book detected and the number of the misplaced book.

<figure align="center">
  <img src="https://github.com/snowlunatic/image/assets/115797946/9bb3a1d9-ee33-4774-a74a-5bca9e234009" style="width:70%;">
  <figcaption><em>Fig17. Wrong Alphabet</em></figcaption>
</figure>



|              | Book 1 | Book 2 | Book 3 | <u>*Book 4*</u> | <u>*Book 5*</u> | Book 6 |
| ------------ | :----: | :----: | :----: | :-------------: | :-------------: | :----: |
| Category     |  5.12  |  5.12  |  5.12  |  *<u>5.12</u>*  |  *<u>5.12</u>*  |  5.12  |
| Alphabet     |   D    |   F    |   F    |   <u>*G*</u>    |   <u>*G*</u>    |   F    |
| Sub-Category |   3    |   3    |   32   |   <u>*35*</u>   |   <u>*35*</u>   |   44   |
| Year         |  2004  |  2005  |  2003  |  <u>*2002*</u>  |  <u>*2002*</u>  |  2011  |



##### "Wrong Sub-Category":

​	When the misplaced sub_category is detected it will bound the misplaced book and show the location it should be with and arrow on the upper side of the image. 

<figure align="center">
  <img src="https://github.com/snowlunatic/image/assets/115797946/902b19e9-77c1-4e97-9c13-e26c70a6e232" style="width:70%;">
  <figcaption><em>Fig18. Wrong Sub_Category</em></figcaption>
</figure>



|              | Book 1 | Book 2 | Book 3 | Book 4 | Book 5 | <u>*Book 6*</u> | Book 7 |
| :----------- | :----: | :----: | :----: | :----: | :----: | :-------------: | :----: |
| Category     |  4.6   |  4.6   |  4.6   |  4.6   |  4.6   |  <u>*4.6*</u>   |  4.6   |
| Alphabet     |   S    |   T    |   T    |   T    |   T    |   <u>*T*</u>    |   T    |
| Sub-Category |   48   |   36   |   36   |   36   |  361   |   <u>*36*</u>   |   38   |
| Year         |  1991  |  1981  |  1989  |  1999  |  1996  |  <u>*1996*</u>  |  2009  |



##### "Wrong year":

​	Lastly when sequence of the year is wrong, same as the wrong sub-category, it will bound and show the corrected location of the book.

<figure align="center">
  <img src="https://github.com/snowlunatic/image/assets/115797946/6ec68be3-59ad-448b-ba9e-a700ae2f417d" style="width:70%;">
  <figcaption><em>Fig19. Wrong Year</em></figcaption>
</figure>



|              | Book 1  | *<u>Book 2</u>*  | Book 3  | Book 4  | Book 5  | Book 6  |
| :----------- | :-----: | :--------------: | :-----: | :-----: | :-----: | :-----: |
| Category     | 150.195 | <u>*150.195*</u> | 150.195 | 150.195 | 150.195 | 150.195 |
| Alphabet     |    G    |    <u>*G*</u>    |    G    |    G    |    G    |    G    |
| Sub-Category |   39    |   <u>*73*</u>    |   73    |   73    |   76    |   82    |
| Year         |  2010   |  <u>*2001*</u>   |  1999   |  1999   |  2013   |  2003   |



## Evaluation

​	Evaluation will be in two parts: 1. Book detection and 2. Text detection. Book detection validation can be inferring validation of the `Yolov8x` and text detection validation as the validation of the smaller rearranged ROI and simultaneously `Goolge Cloud Vision`.  The evaluation was examined with 20 different random data which is taken from the library.

#### Book detection validation

Accuracy over image (even a single miss does not count): 
$$
\frac{16(correct\, detection)}{20(number\, of\, image)} = 80\%
$$
Accuracy over whole books (individual book counts):
$$
\frac{134(correct\,detection)}{144(true\,detection)} = 93\%
$$


#### Text detection validation

Accuracy over image (even a single miss does not count): 
$$
\frac{6(correct\,detection)}{15(number\,of\,text\,image)} = 40\%
$$
Accuracy over whole books (individual text counts):
$$
\frac{68(correct\, detection)}{83(number\,of\,individual\,texts)}=82\%
$$
​	

​	In the system implemented in this experiment, an Object Detection Model is used to select the Region of Interest (ROI), and preprocessing is performed in this area to carry out Text Detection. Both models play a crucial role in the system's performance, so even if one model is inaccurate, system malfunction frequently occurs. Additionally, since the ROI is selected as a rectangle, if the book is tilted or the image's vertical alignment is incorrect, an incorrect ROI may be detected, making Text Detection impossible. Furthermore, even if the book is well detected, there were cases where the label was cut off when setting the ROI with an additional algorithm to view the label. Therefore, attaching the label horizontally on each book or applying the Warp Perspective method to each book could result in a more robust system.

​	It was also found that when the book is thin, it is difficult to detect all the information on the label. Thus, if the labels are attached in a way that ensures they are well-recognized, better performance could be achieved.



## Reference

[Gitbook](https://ykkim.gitbook.io/dlip) - YKKim

[Github](https://github.com/ykkimhgu/DLIP_doc) - YKKim

[Google Cloud Vision](https://cloud.google.com/functions/docs/tutorials/ocr?hl=ko)

